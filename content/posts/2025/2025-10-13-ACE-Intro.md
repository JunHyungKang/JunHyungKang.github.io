---
title: "AI 에이전트의 진화: 프롬프트에서 컨텍스트 엔지니어링까지 (ACE를 곁들인)"
date: "2025-10-13"
teaser: "GPT 등장 이후 AI 에이전트의 발전 흐름을 짚어보고, 모델 외부에서 성능을 향상시키는 최신 연구인 Agentic Context Engineering (ACE)을 소개합니다."
tags:
  - Agent
  - Context Engineering
  - ACE
  - LLM
  - AI Engineering
---

## 들어가며: 모델 밖에서 AI 에이전트를 진화시키는 법

안녕하세요. SK AX의 소리지르는비버 입니다.
최근 AI 에이전트 분야에서는 모델 가중치를 직접 수정하지 않고도 성능을 향상시키는 연구가 주요 트렌드중 하나로 자리 잡고 있습니다.
이 흐름을 공유하고 싶었지만, 마땅한 대표 사례를 찾기 어려웠습니다.
그러던 중, 최근 가장 주목받는 '**Agentic Context Engineering (ACE)**' 연구를 발견했고, 이는 제가 생각하는 방향성과 비슷한 점이 있어서,
GPT 등장 이후 Agent의 모델링 트렌드가 어떻게 발전해왔는지에 대한 저의 시각을 함께 정리해 공유하면서 공유하고자 합니다.

> 본격적인 이야기에 앞서, 저는 현재 조직에서 생성형 AI를 활용한 에이전트 개발을 담당하고 있습니다.
> 따라서 모델 가중치를 직접 수정하는 것 외의 영역, 즉 **에이전트 모델링**을 통한 성능 향상에 좀 더 편향된 시각을 가질 수 있음을 미리 말씀드립니다.
> 물론, 이것이 모델 레이어의 설계나 학습보다 더 중요하다고 주장하는 것은 아닙니다.
> 다만, 실제 에이전틱 서비스에서 모델 외부의 아키텍처 또한 성능과 품질을 좌우하는 매우 중요한 부분이라는 사실을 강조하고 싶습니다.
> (**결국 기본 모델의 성능이 전체 시스템의 상한선(upper bound)을 결정하는 것 또한 명백한 사실입니다.**)


## LLM 애플리케이션의 진화: 하나의 흐름으로 돌아보기

ACE의 등장이 왜 자연스러운 흐름인지 이해하기 위해, GPT등장 이후 제가 개인적으로 느낀 기술 트렌드를 간략하게 되짚어 보겠습니다.

### 1️⃣ 프롬프트 엔지니어링의 시대: 완벽한 명령어를 찾아서

초기 LLM은 컨텍스트 크기가 매우 작았기 때문에, 사람이 한 글자 한 글자 공들여 작성한 '완벽한 프롬프트'에 많은 것을 의존했습니다.
'프롬프트 엔지니어'라는 직업이 생겨날 정도로, 잘 만든 프롬프트를 자산으로 축적하는 것이 문제 해결의 핵심이었습니다.

![프롬프트 엔지니어](/images/ace-1.jpg)
[이미지 출처](https://www.aitimes.com/news/articleView.html?idxno=169983)

### 2️⃣ RAG(검색 증강 생성)의 부상: 환각과의 전쟁

하지만 완벽한 프롬프트만으로는 비즈니스 환경의 환각(Hallucination)을 해결할 수 없었습니다.
이를 극복하기 위해 외부 데이터베이스에서 관련 정보를 검색해 컨텍스트에 주입하는 RAG 방식이 주류로 자리 잡았고, 수많은 Advanced RAG 기법들이 등장했습니다.

![advanced rag](/images/ace-2.jpg)
출처: [Gao, Yunfan, et al. "Retrieval-augmented generation for large language models: A survey." arXiv preprint arXiv:2312.10997 2 (2023).](https://arxiv.org/pdf/2407.21059)

### 3️⃣ 파이프라인 최적화의 시대: DSPy의 등장

프롬프트, RAG 파라미터 등 튜닝해야 할 요소들이 늘어나자, 전체 파이프라인을 사람이 일일이 최적화하기 어려워졌습니다.
DSPy와 같은 프레임워크는 이러한 End-to-End 최적화를 프로그램적으로 자동화하려는 시도였습니다.
(참고: [수작업 프롬프트 엔지니어링을 넘어서: DSPy란?](https://devocean.sk.com/search/techBoardDetail.do?ID=166043&query=%EC%86%8C%EB%A6%AC%EC%A7%80%EB%A5%B4%EB%8A%94%EB%B9%84%EB%B2%84&searchData=&page=&subIndex=&idList=&boardType=undefined&searchText=&techType=&searchDataSub=&searchDataMain=&writerID=&comment=))

### 4️⃣ 워크플로우와 에이전트의 태동: 복잡한 Task를 향하여

더 복잡한 Task에 도전하면서, 여러 LLM 추론 단계를 연결하는 '워크플로우 (Workflow)' 또는 '에이전틱 서비스 (Agentic Service)' 개념이 각광받기 시작했습니다.
초기에는 정해진 워크플로우(DAG)를 따라 단방향으로 처리되다가, 스스로 결과를 평가하고 수정하는 '성찰(Reflection)' 개념이 추가되며 점차 고도화되었습니다.
이후 ReAct와 같은 에이전틱 추론 모듈이 강력해지면서, 워크플로우의 일부를 자율적인 **에이전트**로 대체하는 흐름이 생겨났습니다.

![agent](/images/ace-3.jpg)
(이미지 출처: [https://github.com/humanlayer/12-factor-agents/blob/main/img/1a5-agent-scope-grow.gif](https://github.com/humanlayer/12-factor-agents/blob/main/img/1a5-agent-scope-grow.gif))
(참고: [Agentic AI 개념 정리: 에이전트와 워크플로우의 스펙트럼](https://devocean.sk.com/search/techBoardDetail.do?ID=167483&query=%EC%86%8C%EB%A6%AC%EC%A7%80%EB%A5%B4%EB%8A%94%EB%B9%84%EB%B2%84&searchData=&page=&subIndex=&idList=&boardType=undefined&searchText=&techType=&searchDataSub=&searchDataMain=&writerID=&comment=))

### 5️⃣ 현재: 하이브리드 에이전트 서비스와 '컨텍스트'의 부상

현재 대부분의 실용적인 시스템은 정해진 워크플로우와 자율적인 에이전트를 결합한 '하이브리드' 형태입니다.
이 구조에서 에이전트의 성능을 차별화하는 핵심은 과거의 '워크플로우 설계 능력'을 넘어, **에이전트 간의 컨텍스트 엔지니어링**과 **서비스 레벨의 메모리 관리** 능력으로 옮겨가고 있습니다.

이러한 큰 흐름 속에서, **Agentic Context Engineering (ACE)** 는 바로 이 'context engineering'을 통해 모델 가중치 업데이트 없이도
에이전트의 성능을 극적으로 향상시키는 구체적인 방법론을 제시합니다.

## Agentic Context Engineering (ACE)

[Zhang, Qizheng, et al. "Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models." arXiv preprint arXiv:2510.04618 (2025).](https://arxiv.org/pdf/2510.04618)

### ACE란 무엇인가? 컨텍스트를 '살아있는 플레이북'으로

ACE는 에이전트에게 주어지는 컨텍스트(시스템 프롬프트, 메모리 등)를 일회성 입력이 아닌,
**경험을 통해 지속적으로 진화하고 풍부해지는 '살아있는 플레이북(Living Playbook)'** 으로 다룹니다.

![agent](/images/ace-4.jpg)

이는 Dynamic Cheatsheet이라는 이전 연구의 적응형 메모리 개념을 발전시킨 것입니다.
참고: [Suzgun, Mirac, et al. "Dynamic cheatsheet: Test-time learning with adaptive memory." arXiv preprint arXiv:2504.07952 (2025).](https://arxiv.org/pdf/2504.07952?)

## 기존 컨텍스트 관리 방식의 문제점

ACE는 기존 방식의 두 가지 고질적인 문제, **'간결성 편향(Brevity Bias)'**과 **'컨텍스트 붕괴(Context Collapse)'**를 해결하는 데 집중합니다.
전자는 중요한 세부 정보가 요약 과정에서 사라지는 문제이며, 후자는 반복적인 재작성으로 인해 정보가 점차 왜곡되고 손실되는 현상입니다.

논문의 아래 이미지는 이런 현상을 극적으로 보여줍니다.
그래프를 보면, 에이전트가 작업을 수행하며(adaptation steps) 유용한 정보를 컨텍스트에 꾸준히 추가하여
토큰 수가 18,000개 이상으로 증가하고, 정확도 역시 66.7%까지 상승하는 것을 볼 수 있습니다.

![Context Collapse Graph](/images/ace-5.jpg)

하지만 약 60번째 단계에서, 컨텍스트를 요약하고 재작성하는 과정이 발생하자 토큰 수는 122개로 급감합니다.
이때 중요한 세부 정보와 맥락이 대거 소실되면서 정확도는 오히려 초기 컨텍스트가 없던 상태(63.7%)보다도 낮은 57.1%로 추락합니다.

이는 마치 '말 전달 놀이'처럼, 반복되는 요약 과정이 원래의 풍부했던 지침을 의미 없는 정보로 퇴화시키는 현상을 시각적으로 증명하는 것입니다.
ACE는 바로 이러한 정보의 점진적인 손실을 막기 위해 설계되었습니다.

![funny](/images/ace-6.jpg)

## ACE의 구성 요소: Generator-Reflector-Curator

ACE는 Generator, Reflector, Curator라는 세 개의 독립된 모듈이 유기적으로 협력하는 순환 구조를 가집니다.

![overview](/images/ace-7.jpg)

### 1. Generator

현재 버전의 '플레이북'을 기반으로 실제 작업을 수행하고, 그 과정을 상세한 **추론 궤적(trace)** 으로 기록합니다. (아래는 프롬프트 예시)

![generator](/images/ace-8.jpg)

### 2. Reflector

Generator가 남긴 추론 궤적을 비판적으로 분석하여, 성공과 실패로부터 구체적이고 실행 가능한 **'교훈(insight)'** 을 추출합니다. (아래와 같은 structured 구조로 추출)

![Reflector](/images/ace-9.jpg)

### 3. Curator

Reflector가 추출한 교훈을 구조화된 '델타 컨텍스트(delta context)' 항목으로 변환하여, 기존 플레이북에 체계적으로 통합합니다.
이 과정은 LLM이 아닌 결정론적(deterministic) 로직으로 수행되어 '컨텍스트 붕괴'를 원천적으로 방지합니다.

![Curator](/images/ace-10.jpg)

## ACE를 강력하게 만드는 두 가지 핵심 메커니즘

### 1. 점진적 델타 업데이트 (Incremental Delta Updates)

플레이북 전체를 다시 쓰는 대신, 고유 ID와 메타데이터를 가진 작은 '불릿(bullet)' 단위로 국소적인 수정만 수행하여 컨텍스트 붕괴를 막고 안정성을 보장합니다.

### 2. 성장 및 정제 메커니즘 (Grow-and-Refine)

새로운 교훈을 추가하여 플레이북을 '성장(Grow)'시키면서도, 주기적으로 중복되거나 불필요한 항목을 제거하여 플레이북을 '정제(Refine)'합니다.
이때 중복 제거는 의미론적 임베딩을 활용합니다.

## 실험 결과

고성능 자가 개선: 별도의 정답 레이블 없이, 오직 실행 피드백만으로 학습하여 AppWorld 벤치마크에서 최대 17.1%의 정확도 향상을 달성했습니다.

![result1](/images/ace-11.jpg)

압도적인 효율성: 기존 컨텍스트 적응 방식 대비 엄청난 차이로 지연 시간을 단축하고, 토큰 관련 비용을 크게 절감했습니다.

![result2](/images/ace-12.jpg)

## 결론: 모델이 아닌, 컨텍스트(도) 엔지니어링하라

결론적으로, ACE는 에이전트의 지능이 더 이상 모델의 크기나 가중치에만 의존하는 것이 아니라,
얼마나 정교하게 컨텍스트를 설계하고 진화시키는가에 달려있다는 중요한 메시지를 던집니다.

이 연구는 에이전트의 성능을 높이기 위해 반드시 모델을 재학습시켜야 하는 것은 아니며,
모델 외부에서 '컨텍스트'라는 살아있는 플레이북을 어떻게 설계하고 성장시키는가에 따라 얼마든지 차별화된 성능을 이끌어낼 수 있다는 사실을 증명합니다.
특히, KV 캐시 재사용 등 최신 서빙 인프라 기술이 긴 컨텍스트 처리 비용을 계속해서 낮추고 있어,
ACE와 같이 '컨텍스트가 풍부한' 접근 방식은 점점 더 현실적이고 강력한 대안이 되고 있습니다.

![price](/images/ace-13.jpg)

이는 서론에서 짚어본 GPT 이후의 기술 발전 흐름과 정확히 일치합니다.
에이전트에게 더 많은 자율성을 부여하는 현재의 트렌드 속에서, 서비스의 성능과 품질을 차별화하는 핵심 경쟁력은 이제 **'Context Engineering'** 과 **'메모리 관리'** 가 되고 있습니다.

물론, ACE의 현재 제안은 단일 에이전트 범위에 집중되어 있습니다.
AgentFly, Agent Workflow Memory 등 다른 메모리 기반 방법론들과 비교했을 때 시스템 프롬프트까지 포함하는 더 넓은 컨텍스트를 다루지만,
여러 에이전트와 정적인 워크플로우가 결합된 하이브리드 방식의 비즈니스 서비스에 바로 도입하기 위해서는 추가적인 설계가 필요할 것입니다.

그럼에도 불구하고, ACE는 모델 외부에서 에이전트의 성능을 극적으로 향상시키는 구체적인 청사진을 제시하며, AI 에이전트 개발의 새로운 방향을 여는 중요한 연구라고 할 수 있습니다.
이 글이 AI 에이전트의 새로운 가능성을 모색하는 모든 분들께 유용한 인사이트가 되기를 바랍니다.

감사합니다.
